{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd724011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, roc_auc_score,accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import eli5\n",
    "import ast\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from pretty_confusion_matrix import pp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83af937",
   "metadata": {},
   "outputs": [],
   "source": [
    "plasma_rf=pd.read_csv(\"R/GEO_count/pan_train2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418b4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plasma_rf=plasma_rf.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419c4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = plasma_rf.drop(columns=['group'])\n",
    "y_train = plasma_rf['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "931b15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"R/GEO_count/pan_test2.csv\")\n",
    "test=pd.read_csv(\"R/GEO_count/tissue_test2.csv\")\n",
    "test=pd.read_csv(\"R/GEO_count/plasma_test2.csv\")\n",
    "test=pd.read_csv(\"R/GEO_count/exosome_test2.csv\")\n",
    "test=pd.read_csv(\"R/GEO_count/exosome_test2_CH.csv\")\n",
    "test=pd.read_csv(\"R/GEO_count/exosome_test2_BC.csv\")\n",
    "#independent cohort\n",
    "test=pd.read_csv(\"R/GEO_count/GSE62182_rf.csv\")\n",
    "test=pd.read_csv(\"R/GEO_count/GSE83527_rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b1be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a0db9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test.drop(columns=['group'])\n",
    "y_test=test['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf_classifier.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "sorted_importances, sorted_features = zip(*sorted(zip(feature_importances, feature_names), reverse=True))\n",
    "for feature, importance in zip(sorted_features, sorted_importances):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Features': sorted_features, 'Importances': sorted_importances})\n",
    "\n",
    "# Sort the DataFrame by Importances\n",
    "df = df.sort_values('Importances', ascending=False)\n",
    "\n",
    "# Bar Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importances', y='Features', data=df,palette='YlGnBu')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbfad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200,300],\n",
    "    'max_features': ['sqrt', 2, 3, 4, 5],\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "   'min_samples_leaf': [1, 2, 3],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b80fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid,\n",
    "                           cv=5, n_jobs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params = {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ba27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_classifier = RandomForestClassifier(**best_params,random_state=42)\n",
    "best_rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c002ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = best_rf_classifier.score(X_train, y_train)\n",
    "print(\"train set accuracy: \", accuracy_train)\n",
    "\n",
    "average_cv_accuracy = grid_search.best_score_\n",
    "print(\"Average CV accuracy: \", average_cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c645933",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = best_rf_classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Test set accuracy: \", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = best_rf_classifier.predict_proba(X_train)[:, 1]\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_pred_proba_train, pos_label='tumor')\n",
    "auc_value_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "print(\"AUC_train:\",auc_value_train)\n",
    "youden_J_train = tpr_train - fpr_train\n",
    "\n",
    "# Locate the index of the largest J statistic\n",
    "ix = np.argmax(youden_J_train)\n",
    "optimal_threshold_train = thresholds_train[ix]\n",
    "\n",
    "print('Best Threshold=%f, Youden J=%.3f' % (optimal_threshold_train, youden_J_train[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8abf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_test = best_rf_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_pred_proba_test, pos_label='tumor')\n",
    "auc_value_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "print(\"AUC_test:\",auc_value_test)\n",
    "youden_J_test = tpr_test - fpr_test\n",
    "\n",
    "# Locate the index of the largest J statistic\n",
    "ix_test = np.argmax(youden_J_test)\n",
    "optimal_threshold_test = thresholds_test[ix_test]\n",
    "\n",
    "print('Best Threshold=%f, Youden J=%.3f' % (optimal_threshold_test, youden_J_test[ix_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold at 0.5\n",
    "y_pred_train=best_rf_classifier.predict(X_train)\n",
    "f1_train=f1_score(y_train,y_pred_train,pos_label='tumor')\n",
    "precision_train_score = precision_score(y_train, y_pred_train, pos_label='tumor')\n",
    "recall_train_score = recall_score(y_train, y_pred_train, pos_label='tumor')\n",
    "print(f\"F1-Score_train: {f1_train}\")\n",
    "print(f\"Precision_train: {precision_train_score}\")\n",
    "print(f\"Recall_train: {recall_train_score}\")\n",
    "\n",
    "y_pred_test=best_rf_classifier.predict(X_test)\n",
    "f1_test=f1_score(y_test,y_pred_test,pos_label='tumor')\n",
    "precision_test_score = precision_score(y_test, y_pred_test, pos_label='tumor')\n",
    "recall_test_score = recall_score(y_test, y_pred_test, pos_label='tumor')\n",
    "print(f\"F1-Score_test: {f1_test}\")\n",
    "print(f\"Precision_test: {precision_test_score}\")\n",
    "print(f\"Recall_test: {recall_test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_train, recall_train, thresholds_train = precision_recall_curve(y_train, y_pred_proba_train,pos_label='tumor')\n",
    "f1_scores_train = 2 * (precision_train * recall_train) / (precision_train + recall_train)\n",
    "# Handle division by zero in case precision and recall are both zero\n",
    "f1_scores_train = np.nan_to_num(f1_scores_train)\n",
    "\n",
    "optimal_idx_train = np.argmax(f1_scores_train)\n",
    "optimal_threshold_train = thresholds_test[optimal_idx_train]\n",
    "best_f1_score_train = f1_scores_train[optimal_idx_train] \n",
    "print(\"Optimal threshold:\", optimal_threshold_train)\n",
    "print(\"best f score:\", best_f1_score_train)\n",
    "\n",
    "\n",
    "y_pred_optimal_threshold_train = np.where(y_pred_proba_train >= optimal_threshold_train, \"tumor\", \"normal\")\n",
    "\n",
    "tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_pred_optimal_threshold_train).ravel()\n",
    "\n",
    "ppv_train = tp_train / (tp_train + fp_train) if (tp_train + fp_train) != 0 else 0\n",
    "\n",
    "# Negative Predictive Value\n",
    "npv_train = tn_train / (tn_train + fn_train) if (tn_train + fn_train) != 0 else 0\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "sensitivity_train = tp_train / (tp_train + fn_train) if (tp_train + fn_train) != 0 else 0\n",
    "\n",
    "# Specificity\n",
    "specificity_train = tn_train / (tn_train + fp_train) if (tn_train + fp_train) != 0 else 0\n",
    "\n",
    "#AUPRC\n",
    "auprc_train = auc(recall_train, precision_train)\n",
    "print(\"auprc_train:\", auprc_train)\n",
    "\n",
    "print(f\"PPV/Precision: {ppv_train}\")\n",
    "print(f\"NPV: {npv_train}\")\n",
    "print(f\"Sensitivity/Recall: {sensitivity_train}\")\n",
    "print(f\"Specificity: {specificity_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test, recall_test, thresholds_test = precision_recall_curve(y_test, y_pred_proba_test,pos_label='tumor')\n",
    "f1_scores_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
    "# Handle division by zero in case precision and recall are both zero\n",
    "f1_scores_test = np.nan_to_num(f1_scores_test)\n",
    "\n",
    "optimal_idx_test = np.argmax(f1_scores_test)\n",
    "optimal_threshold_test = thresholds_test[optimal_idx_test]\n",
    "best_f1_score_test = f1_scores_test[optimal_idx_test] \n",
    "print(\"Optimal threshold:\", optimal_threshold_test)\n",
    "print(\"best f score:\", best_f1_score_test)\n",
    "\n",
    "\n",
    "y_pred_optimal_threshold_test = np.where(y_pred_proba_test >= optimal_threshold_test, \"tumor\", \"normal\")\n",
    "\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_pred_optimal_threshold_test).ravel()\n",
    "\n",
    "ppv_test = tp_test / (tp_test + fp_test) if (tp_test + fp_test) != 0 else 0\n",
    "\n",
    "# Negative Predictive Value\n",
    "npv_test = tn_test / (tn_test + fn_test) if (tn_test + fn_test) != 0 else 0\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "sensitivity_test = tp_test / (tp_test + fn_test) if (tp_test + fn_test) != 0 else 0\n",
    "\n",
    "# Specificity\n",
    "specificity_test = tn_test / (tn_test + fp_test) if (tn_test + fp_test) != 0 else 0\n",
    "\n",
    "\n",
    "#AUPRC\n",
    "auprc_test = auc(recall_test, precision_test)\n",
    "print(\"auprc_test:\", auprc_test)\n",
    "\n",
    "print(f\"PPV/Precision: {ppv_test}\")\n",
    "print(f\"NPV: {npv_test}\")\n",
    "print(f\"Sensitivity/Recall: {sensitivity_test}\")\n",
    "print(f\"Specificity: {specificity_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC curve\n",
    "# Assuming fpr_val, tpr_val, and auc_val contain the FPR, TPR, and AUC for the validation set\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# plot ROC curve for the train set\n",
    "plt.plot(fpr_train, tpr_train, label=f'Train Set AUC = {auc_value_train:.2f}')\n",
    "\n",
    "# Plot ROC curve for the test set\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test Set AUC = {auc_value_test:.2f}')\n",
    "\n",
    "# Plot ROC curve for the validation set\n",
    "# plt.plot(fpr_val, tpr_val, label=f'Validation Set AUC = {auc_value_val:.2f}', linestyle='-.')  # You can change the linestyle as you like\n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "\n",
    "# Labels, title, and other settings\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)', fontweight='bold')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)', fontweight='bold')\n",
    "legend = plt.legend(loc='lower right')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision-recall\n",
    "precision_train, recall_train, _ = precision_recall_curve(y_train, y_pred_proba_train,pos_label='tumor')\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_pred_proba_test,pos_label='tumor')\n",
    "auprc_train = auc(recall_train, precision_train)\n",
    "print(\"auprc_train:\", auprc_train)\n",
    "auprc_test = auc(recall_test, precision_test)\n",
    "print(\"auprc_test:\", auprc_test)\n",
    "\n",
    "# precision_val, recall_val, _ = precision_recall_curve(y_val, y_pred_proba_val,pos_label='tumor')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(recall_train, precision_train, marker='.', label=f'Train Set AUCPRC = {auprc_train:.2f}', color='blue')\n",
    "\n",
    "# Plot for test set\n",
    "plt.plot(recall_test, precision_test, marker='.', label=f'Test Set AUCPRC = {auprc_test:.2f}', color='green')\n",
    "\n",
    "# Plot for validation set\n",
    "# plt.plot(recall_val, precision_val, marker='.', label='Validation', color='red')\n",
    "\n",
    "# Labeling the axes and setting the title\n",
    "plt.xlabel('Recall',fontweight='bold')\n",
    "plt.ylabel('Precision',fontweight='bold')\n",
    "#plt.title('Exosome Cohort benign vs cancer',fontweight='bold')\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_cm(cm):\n",
    "    # Extracting values from the confusion matrix\n",
    "    TP = cm[0, 0]\n",
    "    FN = cm[0, 1]\n",
    "    FP = cm[1, 0]\n",
    "    TN = cm[1, 1]\n",
    "\n",
    "    # Calculating Sensitivity and Specificity\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    \n",
    "\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30452ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p is the optimal value\n",
    "y_pred_train_labels = [\"tumor\" if p >=  else \"normal\" for p in y_pred_proba_train]\n",
    "y_pred_test_labels = [\"tumor\" if p >=  else \"normal\" for p in y_pred_proba_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97439995",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, y_pred_test_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_test)\n",
    "sensitivity_test, specificity_test = compute_metrics_from_cm(cm_test)\n",
    "print(\"sensitivity_test, specificity_test:\")\n",
    "print(sensitivity_test, specificity_test)\n",
    "\n",
    "cm_train = confusion_matrix(y_train, y_pred_train_labels)\n",
    "sensitivity_train, specificity_train = compute_metrics_from_cm(cm_train)\n",
    "print(\"sensitivity_train, specificity_train:\")\n",
    "print(sensitivity_train, specificity_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe819ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes=None, figsize=(7, 5), text_size=14):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    n_classes = cm.shape[0]\n",
    "\n",
    "    if classes is None:\n",
    "        classes = [str(i) for i in range(n_classes)]\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cax = ax.matshow(cm_norm, cmap=plt.cm.Blues)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.set(title=' threhold', \n",
    "           xlabel='Predicted Label', \n",
    "           ylabel='True Label', \n",
    "           xticks=np.arange(n_classes), \n",
    "           yticks=np.arange(n_classes), \n",
    "           xticklabels=classes, \n",
    "           yticklabels=classes)\n",
    "    ax.xaxis.set_label_position('bottom')\n",
    "    ax.xaxis.tick_bottom()\n",
    "\n",
    "    ax.yaxis.label.set_size(text_size)\n",
    "    ax.xaxis.label.set_size(text_size)\n",
    "    ax.title.set_size(text_size * 1.2)\n",
    "    \n",
    "    threshold = (cm_norm.max() + cm_norm.min()) / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f'{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)', \n",
    "                 horizontalalignment='center', \n",
    "                 color='white' if cm_norm[i, j] > threshold else 'black', \n",
    "                 size=text_size)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca294c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Normal', 'Tumor']\n",
    "plot_confusion_matrix(y_test, y_pred_test_labels, classes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
